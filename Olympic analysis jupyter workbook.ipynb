{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Olympic data set analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This analysis explores the relationship between a country's economic status and its Olympic performance, focusing on whether wealthier nations perform better in the Games and whether hosting the Olympics boosts the economy. The data, spanning from the 2000 to 2023 Olympic Games, will include medal counts and GDP figures. The ETL process will transform raw CSV files into fact and dimension tables, which will be organized in a data warehouse using PGAdmin. Atoti will be used for visualizations to answer these key questions.\n",
    "\n",
    "### Main questions we aim to answer:\n",
    "\n",
    "1. Do Countries with a higher gdp perform bettter at the olympics. \n",
    "2. How does hosting the olympic games, affect the economy GDP.\n",
    "\n",
    "### What kind of stakeholders would be interested in analysis:\n",
    "\n",
    "- Government & Policy Makers: To guide investment in sports and assess economic impacts.\n",
    "\n",
    "- National Olympic Committees (NOCs): For strategic resource allocation and performance evaluation.\n",
    "\n",
    "- Sports Federations: To advocate for funding based on performance data.\n",
    "\n",
    "- Economic Analysts: To assess the economic impact of hosting the Olympics.\n",
    "\n",
    "- IOC & Event Organizers: To evaluate benefits of hosting and improve future bids.\n",
    "\n",
    "- Sponsors & Investors: For data-driven sponsorship and marketing decisions.\n",
    "\n",
    "- Media & Journalists: To provide insights and compelling stories to the public.\n",
    "\n",
    "- Academics & Researchers: To explore the relationship between economy and sports performance.\n",
    "\n",
    "\n",
    "![title](image.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starnet and Granuality of the datawarehouse\n",
    "\n",
    "To make the analysis possible we have to create a datawarehouse schema and starnet that will form the basis for our dimensions and our queries.\n",
    "\n",
    "for this dataset we aim to have 5 dimension tables and 1 fact key ordered as follows:\n",
    "\n",
    "### Data Warehouse Schema\n",
    "\n",
    "The following tables will be created in the data warehouse to organize and store the data for Olympic performance and economic indicators (GDP) for each country.\n",
    "\n",
    "1. **dim_country Table**  \n",
    "   Stores information about the countries.  \n",
    "   | Column         | Data Type | Description                   |\n",
    "   |----------------|-----------|-------------------------------|\n",
    "   | `country_id`   | SERIAL    | Primary key                   |\n",
    "   | `country_name` | TEXT      | Name of the country           |\n",
    "   | `continent`    | TEXT      | Continent of the country      |\n",
    "\n",
    "2. **dim_year Table**  \n",
    "   Stores information about the years and the host city for each Olympics.  \n",
    "   | Column       | Data Type | Description                    |\n",
    "   |--------------|-----------|--------------------------------|\n",
    "   | `year_id`    | SERIAL    | Primary key                    |\n",
    "   | `year`       | INTEGER   | Year of the Olympics           |\n",
    "   | `host_city`  | TEXT      | Host city of the event         |\n",
    "\n",
    "3. **dim_event Table**  \n",
    "   Stores details about the sports and events.  \n",
    "   | Column     | Data Type | Description                         |\n",
    "   |------------|-----------|-------------------------------------|\n",
    "   | `event_id` | SERIAL    | Primary key                         |\n",
    "   | `event_name` | TEXT    | Name of the event                   |\n",
    "   | `sport`    | TEXT      | Sport category (e.g., Athletics)    |\n",
    "\n",
    "4. **dim_medal Table** (Optional but useful)  \n",
    "   Stores the types of medals awarded.  \n",
    "   | Column      | Data Type | Description               |\n",
    "   |-------------|-----------|---------------------------|\n",
    "   | `medal_id`  | SERIAL    | Primary key               |\n",
    "   | `medal_type`| TEXT      | Medal type (Gold, Silver, Bronze) |\n",
    "\n",
    "5. **dim_gdp Table**  \n",
    "   Stores GDP data for each country and year.  \n",
    "   | Column      | Data Type | Description               |\n",
    "   |-------------|-----------|---------------------------|\n",
    "   | `gdp_id`    | SERIAL    | Primary key               |\n",
    "   | `country_id`| INTEGER   | Foreign key to `dim_country` |\n",
    "   | `year_id`   | INTEGER   | Foreign key to `dim_year`  |\n",
    "   | `gdp`       | NUMERIC   | GDP value for the country  |\n",
    "\n",
    "6. **fact_medal_counts Table**  \n",
    "   Stores the main measures, including medal counts and GDP.  \n",
    "   | Column        | Data Type | Description                  |\n",
    "   |---------------|-----------|------------------------------|\n",
    "   | `fact_id`     | SERIAL    | Primary key                  |\n",
    "   | `country_id`  | INTEGER   | Foreign key to `dim_country`  |\n",
    "   | `year_id`     | INTEGER   | Foreign key to `dim_year`     |\n",
    "   | `event_id`    | INTEGER   | Foreign key to `dim_event`    |\n",
    "   | `gold_count`  | INTEGER   | Number of Gold medals        |\n",
    "   | `silver_count`| INTEGER   | Number of Silver medals      |\n",
    "   | `bronze_count`| INTEGER   | Number of Bronze medals      |\n",
    "   | `total_medals`| INTEGER   | Total medals won             |\n",
    "   | `gdp`         | NUMERIC   | GDP value for the year       |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL Process \n",
    "Below we conduct the etl, process creating our different dimensions and then fact tables. once we do that we will then connect to a pgadmin remost server and from there build hierachies and so forth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction\n",
    "\n",
    "Since the data was just simplem, csv downlaod the extraction process will just be a series of code where we just load the data into the our staging area the jupyter notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "athlete_medal_data_raw = \"AthleteMedalData.csv\"\n",
    "gdp_data_raw = \"gdp data.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def open_medal_athelte_data(data):\n",
    "    \"\"\" This function will open the original athlete\n",
    "        and medal raw CSV into our staging area, and then\n",
    "        convert it into a Python pandas dataframe. \"\"\"\n",
    "    \n",
    "    datalist = []\n",
    "    with open(data, \"rt\") as raw_ath_med:\n",
    "        reader = csv.reader(raw_ath_med)\n",
    "        next(reader)  # Skip the header row\n",
    "        \n",
    "        for row in reader:\n",
    "            # Ensuring we have the right number of columns\n",
    "            if len(row) == 11:\n",
    "                player_id, Name, Sex, Team, NOC, Year, Season, City, Sport, Event, Medal = row\n",
    "                datalist.append((player_id, Name, Sex, Team, NOC, Year, Season, City, Sport, Event, Medal))\n",
    "    \n",
    "    return datalist\n",
    "\n",
    "# Example usage\n",
    "medal_athelte_data = open_medal_athelte_data(athlete_medal_data_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**medal_data_df_and_formatting** `function`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def medal_data_df_and_formatting(data):\n",
    "    \"\"\" this function Converting data list into pandas dataframe and then \n",
    "        removes all rows with a \"No medal\" string value in the Medal column \"\"\"\n",
    "\n",
    "    # Converting data list into pandas dataframe\n",
    "\n",
    "    athelete_medals_events_df = pd.DataFrame(data, columns = [\"player_id\", \"Name\", \"Sex\", \"Team\", \"NOC\", \"Year\", \"Season\", \"City\", \"Sport\", \"Event\", \"Medal\"])\n",
    "\n",
    "    # Removing all rows with a \"No medal\" string value in the Medal column\n",
    "\n",
    "    athelete_medals_events_df = athelete_medals_events_df[athelete_medals_events_df[\"Medal\"] != \"No medal\"]\n",
    "\n",
    "    return athelete_medals_events_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player_id</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Team</th>\n",
       "      <th>NOC</th>\n",
       "      <th>Year</th>\n",
       "      <th>Season</th>\n",
       "      <th>City</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Event</th>\n",
       "      <th>Medal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Edgar Aabye</td>\n",
       "      <td>M</td>\n",
       "      <td>Denmark/Sweden</td>\n",
       "      <td>DEN</td>\n",
       "      <td>1900</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Paris</td>\n",
       "      <td>Tug-Of-War</td>\n",
       "      <td>Tug-Of-War Men's Tug-Of-War</td>\n",
       "      <td>Gold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>37</td>\n",
       "      <td>Arvo Aaltonen</td>\n",
       "      <td>M</td>\n",
       "      <td>Finland</td>\n",
       "      <td>FIN</td>\n",
       "      <td>1920</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Antwerpen</td>\n",
       "      <td>Swimming</td>\n",
       "      <td>Swimming Men's 200 metres Breaststroke</td>\n",
       "      <td>Bronze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>38</td>\n",
       "      <td>Arvo Aaltonen</td>\n",
       "      <td>M</td>\n",
       "      <td>Finland</td>\n",
       "      <td>FIN</td>\n",
       "      <td>1920</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Antwerpen</td>\n",
       "      <td>Swimming</td>\n",
       "      <td>Swimming Men's 400 metres Breaststroke</td>\n",
       "      <td>Bronze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>41</td>\n",
       "      <td>Paavo Aaltonen</td>\n",
       "      <td>M</td>\n",
       "      <td>Finland</td>\n",
       "      <td>FIN</td>\n",
       "      <td>1948</td>\n",
       "      <td>Summer</td>\n",
       "      <td>London</td>\n",
       "      <td>Gymnastics</td>\n",
       "      <td>Gymnastics Men's Individual All-Around</td>\n",
       "      <td>Bronze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>42</td>\n",
       "      <td>Paavo Aaltonen</td>\n",
       "      <td>M</td>\n",
       "      <td>Finland</td>\n",
       "      <td>FIN</td>\n",
       "      <td>1948</td>\n",
       "      <td>Summer</td>\n",
       "      <td>London</td>\n",
       "      <td>Gymnastics</td>\n",
       "      <td>Gymnastics Men's Team All-Around</td>\n",
       "      <td>Gold</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   player_id            Name Sex            Team  NOC  Year  Season  \\\n",
       "3          3     Edgar Aabye   M  Denmark/Sweden  DEN  1900  Summer   \n",
       "12        37   Arvo Aaltonen   M         Finland  FIN  1920  Summer   \n",
       "13        38   Arvo Aaltonen   M         Finland  FIN  1920  Summer   \n",
       "15        41  Paavo Aaltonen   M         Finland  FIN  1948  Summer   \n",
       "16        42  Paavo Aaltonen   M         Finland  FIN  1948  Summer   \n",
       "\n",
       "         City       Sport                                   Event   Medal  \n",
       "3       Paris  Tug-Of-War             Tug-Of-War Men's Tug-Of-War    Gold  \n",
       "12  Antwerpen    Swimming  Swimming Men's 200 metres Breaststroke  Bronze  \n",
       "13  Antwerpen    Swimming  Swimming Men's 400 metres Breaststroke  Bronze  \n",
       "15     London  Gymnastics  Gymnastics Men's Individual All-Around  Bronze  \n",
       "16     London  Gymnastics        Gymnastics Men's Team All-Around    Gold  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "athlete_medals_df = medal_data_df_and_formatting(open_medal_athelte_data(athlete_medal_data_raw))\n",
    "athlete_medals_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have loaded in the data, let us investigate if there is any missig entries for anyof the fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of        player_id             Name Sex            Team  NOC  Year  Season  \\\n",
       "3              3      Edgar Aabye   M  Denmark/Sweden  DEN  1900  Summer   \n",
       "12            37    Arvo Aaltonen   M         Finland  FIN  1920  Summer   \n",
       "13            38    Arvo Aaltonen   M         Finland  FIN  1920  Summer   \n",
       "15            41   Paavo Aaltonen   M         Finland  FIN  1948  Summer   \n",
       "16            42   Paavo Aaltonen   M         Finland  FIN  1948  Summer   \n",
       "...          ...              ...  ..             ...  ...   ...     ...   \n",
       "252551   4979564    Quincy Wilson   M   United States  USA  2024  Summer   \n",
       "252556   4980004         van Anne   F     Netherlands  NED  2024  Summer   \n",
       "252562   1972077     Isayah Boers   M     Netherlands  NED  2024  Summer   \n",
       "252563   1899865      Kevin Staut   M          France  FRA  2024  Summer   \n",
       "252564   1924402  Charlie Carvell   M   Great Britain  GBR  2024  Summer   \n",
       "\n",
       "             City       Sport                                   Event   Medal  \n",
       "3           Paris  Tug-Of-War             Tug-Of-War Men's Tug-Of-War    Gold  \n",
       "12      Antwerpen    Swimming  Swimming Men's 200 metres Breaststroke  Bronze  \n",
       "13      Antwerpen    Swimming  Swimming Men's 400 metres Breaststroke  Bronze  \n",
       "15         London  Gymnastics  Gymnastics Men's Individual All-Around  Bronze  \n",
       "16         London  Gymnastics        Gymnastics Men's Team All-Around    Gold  \n",
       "...           ...         ...                                     ...     ...  \n",
       "252551      Paris   Athletics                    4 x 400m Relay Mixed  Silver  \n",
       "252556      Paris   Athletics                  Women's 4 x 400m Relay  Silver  \n",
       "252562      Paris   Athletics                    4 x 400m Relay Mixed    Gold  \n",
       "252563      Paris  Equestrian                            Jumping Team  Bronze  \n",
       "252564      Paris   Athletics                    Men's 4 x 400m Relay  Bronze  \n",
       "\n",
       "[38818 rows x 11 columns]>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "athlete_medals_df.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "player_id    0\n",
       "Name         0\n",
       "Sex          0\n",
       "Team         0\n",
       "NOC          0\n",
       "Year         0\n",
       "Season       0\n",
       "City         0\n",
       "Sport        0\n",
       "Event        0\n",
       "Medal        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "athlete_medals_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every element there is no missing entries.\n",
    "We will move unto remove those columns where the, Medal type is \"No medal\" as our analysis will not be focused on collective particpation rates rather on the performance of those countries that particpated. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**year_df_indexing** `function`\n",
    "\n",
    "This function creates a subset of year and city from the athlete_medals_df, \n",
    "naming it year_df and it also resets the index adding a unique identifier year_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def year_df_indexing(dataframe):\n",
    "    \"\"\" This function creates a subset of year and city from the athlete_medals_df, \n",
    "        naming it year_df and it also resets the index adding a unique identifier year_id\"\"\"\n",
    "\n",
    "    year_df  = dataframe[[\"Year\",\"City\"]]\n",
    "    year_df.drop_duplicates(subset=[\"Year\", \"City\"], keep=\"first\", inplace=True)\n",
    "\n",
    "    # adding a unique identifier as an index to the newly made dataframe\n",
    "\n",
    "    year_df = year_df.reset_index()\n",
    "    year_df[\"Year_id\"] = year_df.index\n",
    "    year_df = year_df.drop(columns=[\"index\"])\n",
    "    year_df = year_df[[\"Year_id\",\"Year\",\"City\"]]\n",
    "    \n",
    "\n",
    "    return year_df \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maria\\AppData\\Local\\Temp\\ipykernel_3680\\1243901530.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  year_df.drop_duplicates(subset=[\"Year\", \"City\"], keep=\"first\", inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year_id</th>\n",
       "      <th>Year</th>\n",
       "      <th>City</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1900</td>\n",
       "      <td>Paris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1920</td>\n",
       "      <td>Antwerpen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1948</td>\n",
       "      <td>London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1952</td>\n",
       "      <td>Helsinki</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2008</td>\n",
       "      <td>Beijing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1988</td>\n",
       "      <td>Seoul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1996</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1912</td>\n",
       "      <td>Stockholm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1956</td>\n",
       "      <td>Melbourne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2016</td>\n",
       "      <td>Rio de Janeiro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>2012</td>\n",
       "      <td>London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>2000</td>\n",
       "      <td>Sydney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>2004</td>\n",
       "      <td>Athina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>1980</td>\n",
       "      <td>Moskva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>1984</td>\n",
       "      <td>Los Angeles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>1992</td>\n",
       "      <td>Barcelona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>1936</td>\n",
       "      <td>Berlin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>1906</td>\n",
       "      <td>Athina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>1960</td>\n",
       "      <td>Roma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>1964</td>\n",
       "      <td>Tokyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>1972</td>\n",
       "      <td>Munich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>1924</td>\n",
       "      <td>Paris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>1904</td>\n",
       "      <td>St. Louis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>1932</td>\n",
       "      <td>Los Angeles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>1976</td>\n",
       "      <td>Montreal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>1908</td>\n",
       "      <td>London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>1928</td>\n",
       "      <td>Amsterdam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>1968</td>\n",
       "      <td>Mexico City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>1896</td>\n",
       "      <td>Athina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>1956</td>\n",
       "      <td>Stockholm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>2020</td>\n",
       "      <td>Tokyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>2024</td>\n",
       "      <td>Paris</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year_id  Year            City\n",
       "0         0  1900           Paris\n",
       "1         1  1920       Antwerpen\n",
       "2         2  1948          London\n",
       "3         3  1952        Helsinki\n",
       "4         4  2008         Beijing\n",
       "5         5  1988           Seoul\n",
       "6         6  1996         Atlanta\n",
       "7         7  1912       Stockholm\n",
       "8         8  1956       Melbourne\n",
       "9         9  2016  Rio de Janeiro\n",
       "10       10  2012          London\n",
       "11       11  2000          Sydney\n",
       "12       12  2004          Athina\n",
       "13       13  1980          Moskva\n",
       "14       14  1984     Los Angeles\n",
       "15       15  1992       Barcelona\n",
       "16       16  1936          Berlin\n",
       "17       17  1906          Athina\n",
       "18       18  1960            Roma\n",
       "19       19  1964           Tokyo\n",
       "20       20  1972          Munich\n",
       "21       21  1924           Paris\n",
       "22       22  1904       St. Louis\n",
       "23       23  1932     Los Angeles\n",
       "24       24  1976        Montreal\n",
       "25       25  1908          London\n",
       "26       26  1928       Amsterdam\n",
       "27       27  1968     Mexico City\n",
       "28       28  1896          Athina\n",
       "29       29  1956       Stockholm\n",
       "30       30  2020           Tokyo\n",
       "31       31  2024           Paris"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_dataframe = year_df_indexing(athlete_medals_df)\n",
    "year_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the year dataframe into a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_dataframe.to_csv('dim_year.csv', index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next part is to tranform the athelte medal data into an event dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def event_df_indexing(dataframe):\n",
    "\n",
    "    \"\"\" This function creates a subset of Sport and Event  from the athlete_medals_df, \n",
    "            naming it year_df and it also resets the index adding a unique identifier year_id\"\"\"\n",
    "\n",
    "    event_df = dataframe[[\"Sport\",\"Event\"]]   #creating a subset\n",
    "\n",
    "    event_df.drop_duplicates(subset=[\"Sport\",\"Event\"], keep=\"first\", inplace=True)\n",
    "\n",
    "    event_df = event_df.reset_index()\n",
    "\n",
    "    event_df[\"Event_id\"] = event_df.index\n",
    "\n",
    "    event_df = event_df.drop(columns=[\"index\"])\n",
    "\n",
    "    event_df = event_df[[\"Event_id\", \"Sport\",\"Event\"]]\n",
    "\n",
    "    return event_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maria\\AppData\\Local\\Temp\\ipykernel_3680\\2413774140.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  event_df.drop_duplicates(subset=[\"Sport\",\"Event\"], keep=\"first\", inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Event_id</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Event</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Tug-Of-War</td>\n",
       "      <td>Tug-Of-War Men's Tug-Of-War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Swimming</td>\n",
       "      <td>Swimming Men's 200 metres Breaststroke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Swimming</td>\n",
       "      <td>Swimming Men's 400 metres Breaststroke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Gymnastics</td>\n",
       "      <td>Gymnastics Men's Individual All-Around</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Gymnastics</td>\n",
       "      <td>Gymnastics Men's Team All-Around</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>1086</td>\n",
       "      <td>Swimming</td>\n",
       "      <td>Mixed 4 x 100m Medley Relay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1087</th>\n",
       "      <td>1087</td>\n",
       "      <td>Swimming</td>\n",
       "      <td>Women's 4 x 100m Medley Relay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>1088</td>\n",
       "      <td>Swimming</td>\n",
       "      <td>Women's 4 x 200m Freestyle Relay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1089</th>\n",
       "      <td>1089</td>\n",
       "      <td>Water Polo</td>\n",
       "      <td>Women</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090</th>\n",
       "      <td>1090</td>\n",
       "      <td>Beach Volleyball</td>\n",
       "      <td>Women</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1091 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Event_id             Sport                                   Event\n",
       "0            0        Tug-Of-War             Tug-Of-War Men's Tug-Of-War\n",
       "1            1          Swimming  Swimming Men's 200 metres Breaststroke\n",
       "2            2          Swimming  Swimming Men's 400 metres Breaststroke\n",
       "3            3        Gymnastics  Gymnastics Men's Individual All-Around\n",
       "4            4        Gymnastics        Gymnastics Men's Team All-Around\n",
       "...        ...               ...                                     ...\n",
       "1086      1086          Swimming             Mixed 4 x 100m Medley Relay\n",
       "1087      1087          Swimming           Women's 4 x 100m Medley Relay\n",
       "1088      1088          Swimming        Women's 4 x 200m Freestyle Relay\n",
       "1089      1089        Water Polo                                   Women\n",
       "1090      1090  Beach Volleyball                                   Women\n",
       "\n",
       "[1091 rows x 3 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_df_dataframe = event_df_indexing(athlete_medals_df)\n",
    "event_df_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us create the event dimension csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_df_dataframe.to_csv(\"dim_event.csv\", index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opening and cleaning the gdp data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opening_gdp_raw(data):\n",
    "    \"\"\" this function will open the data for the gdp here we will \n",
    "        define the rows we need only from the years 2000 and up as\n",
    "        that is what we will basinng our analysis upon.\"\"\"\n",
    "    gdp_list = []\n",
    "\n",
    "    with open(data,\"rt\") as gdp_raw:\n",
    "        gdp_raw_csv_read = csv.reader(gdp_raw, delimiter= \",\")\n",
    "\n",
    "        for line in range(5):         # skipping the first 5 rows due them containing metdata dat to the csv.\n",
    "            next(gdp_raw_csv_read) \n",
    "        \n",
    "        for column in gdp_raw_csv_read:\n",
    "            Country_Name = column[0]\n",
    "            Country_Code = column[1]\n",
    "            year_2000 = column[44]\n",
    "            year_2001 = column[45]\n",
    "            year_2002 = column[46]\n",
    "            year_2003 = column[47]\n",
    "            year_2004 = column[48]\n",
    "            year_2005 = column[49]\n",
    "            year_2006 = column[50]\n",
    "            year_2007 = column[51]\n",
    "            year_2008 = column[52]\n",
    "            year_2009 = column[53]\n",
    "            year_2010 = column[54]\n",
    "            year_2011 = column[55]\n",
    "            year_2012 = column[56]\n",
    "            year_2013 = column[57]\n",
    "            year_2014 = column[58]\n",
    "            year_2015 = column[59]\n",
    "            year_2016 = column[60]\n",
    "            year_2017 = column[61]\n",
    "            year_2018 = column[62]\n",
    "            year_2019 = column[63]\n",
    "            year_2020 = column[64]\n",
    "            year_2021 = column[65]\n",
    "            year_2022 = column[66]\n",
    "            year_2023 = column[67]\n",
    "            \n",
    "        \n",
    "\n",
    "            # Append the relevant columns to the list as a tuple\n",
    "            x.append((\n",
    "                Country_Name,\n",
    "                Country_Code,\n",
    "                year_2000, year_2001, year_2002, year_2003, year_2004, year_2005,\n",
    "                year_2006, year_2007, year_2008, year_2009, year_2010, year_2011,\n",
    "                year_2012, year_2013, year_2014, year_2015, year_2016, year_2017,\n",
    "                year_2018, year_2019, year_2020, year_2021, year_2022, year_2023\n",
    "            ))\n",
    "\n",
    "    \n",
    "    return gdp_list  \n",
    "gdp_raw_list =  opening_gdp_raw(gdp_data_raw)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have created out list of gdps for the years 2000 - 2023, the next step is to convert the data into a pandas dataframe.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**gdp_raw_list_to_df** `function`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gdp_raw_list_to_df(data):\n",
    "    \n",
    "    \"\"\" This function converst the gdp raw data list into a pandas's dataframe \"\"\"\n",
    "\n",
    "\n",
    "    gdp_raw_df = pd.DataFrame(data, columns= ['Country_Name',\n",
    "    'Country_Code',\n",
    "    'year_2000', 'year_2001', 'year_2002', 'year_2003', 'year_2004', 'year_2005',\n",
    "    'year_2006', 'year_2007', 'year_2008', 'year_2009', 'year_2010', 'year_2011',\n",
    "    'year_2012', 'year_2013', 'year_2014', 'year_2015', 'year_2016', 'year_2017',\n",
    "    'year_2018', 'year_2019', 'year_2020', 'year_2021', 'year_2022', 'year_2023'])\n",
    "\n",
    "    return gdp_raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country_Name</th>\n",
       "      <th>Country_Code</th>\n",
       "      <th>year_2000</th>\n",
       "      <th>year_2001</th>\n",
       "      <th>year_2002</th>\n",
       "      <th>year_2003</th>\n",
       "      <th>year_2004</th>\n",
       "      <th>year_2005</th>\n",
       "      <th>year_2006</th>\n",
       "      <th>year_2007</th>\n",
       "      <th>year_2008</th>\n",
       "      <th>year_2009</th>\n",
       "      <th>year_2010</th>\n",
       "      <th>year_2011</th>\n",
       "      <th>year_2012</th>\n",
       "      <th>year_2013</th>\n",
       "      <th>year_2014</th>\n",
       "      <th>year_2015</th>\n",
       "      <th>year_2016</th>\n",
       "      <th>year_2017</th>\n",
       "      <th>year_2018</th>\n",
       "      <th>year_2019</th>\n",
       "      <th>year_2020</th>\n",
       "      <th>year_2021</th>\n",
       "      <th>year_2022</th>\n",
       "      <th>year_2023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aruba</td>\n",
       "      <td>ABW</td>\n",
       "      <td>21026.16709</td>\n",
       "      <td>20911.19277</td>\n",
       "      <td>21375.26912</td>\n",
       "      <td>22050.58987</td>\n",
       "      <td>24105.52412</td>\n",
       "      <td>24978.22167</td>\n",
       "      <td>25832.92556</td>\n",
       "      <td>27665.29948</td>\n",
       "      <td>29011.63906</td>\n",
       "      <td>25740.77023</td>\n",
       "      <td>24452.58874</td>\n",
       "      <td>26043.15633</td>\n",
       "      <td>25611.17577</td>\n",
       "      <td>26514.86898</td>\n",
       "      <td>26940.26411</td>\n",
       "      <td>28419.26453</td>\n",
       "      <td>28449.71295</td>\n",
       "      <td>29329.08175</td>\n",
       "      <td>30918.48358</td>\n",
       "      <td>31902.80982</td>\n",
       "      <td>24008.12782</td>\n",
       "      <td>29127.75938</td>\n",
       "      <td>33300.83882</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Africa Eastern and Southern</td>\n",
       "      <td>AFE</td>\n",
       "      <td>715.1425073</td>\n",
       "      <td>633.4733816</td>\n",
       "      <td>633.5202007</td>\n",
       "      <td>819.986705</td>\n",
       "      <td>994.1938544</td>\n",
       "      <td>1130.168938</td>\n",
       "      <td>1235.847125</td>\n",
       "      <td>1379.746756</td>\n",
       "      <td>1439.240924</td>\n",
       "      <td>1404.535948</td>\n",
       "      <td>1622.684093</td>\n",
       "      <td>1757.998404</td>\n",
       "      <td>1724.204053</td>\n",
       "      <td>1696.35604</td>\n",
       "      <td>1678.55361</td>\n",
       "      <td>1498.805084</td>\n",
       "      <td>1346.301281</td>\n",
       "      <td>1485.753579</td>\n",
       "      <td>1558.612079</td>\n",
       "      <td>1508.486886</td>\n",
       "      <td>1356.088871</td>\n",
       "      <td>1545.956697</td>\n",
       "      <td>1642.432039</td>\n",
       "      <td>1672.505957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>180.1883694</td>\n",
       "      <td>142.9033644</td>\n",
       "      <td>182.1740382</td>\n",
       "      <td>199.6432265</td>\n",
       "      <td>221.8305307</td>\n",
       "      <td>254.115276</td>\n",
       "      <td>274.0153923</td>\n",
       "      <td>376.3182996</td>\n",
       "      <td>382.5338072</td>\n",
       "      <td>453.3873851</td>\n",
       "      <td>562.4992216</td>\n",
       "      <td>608.7388504</td>\n",
       "      <td>653.4174749</td>\n",
       "      <td>638.733181</td>\n",
       "      <td>626.5129291</td>\n",
       "      <td>566.8811297</td>\n",
       "      <td>523.053012</td>\n",
       "      <td>526.140801</td>\n",
       "      <td>492.090631</td>\n",
       "      <td>497.7414313</td>\n",
       "      <td>512.055098</td>\n",
       "      <td>355.7778264</td>\n",
       "      <td>352.6037331</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Africa Western and Central</td>\n",
       "      <td>AFW</td>\n",
       "      <td>527.2025617</td>\n",
       "      <td>539.2257488</td>\n",
       "      <td>627.0959153</td>\n",
       "      <td>706.4765613</td>\n",
       "      <td>850.0835822</td>\n",
       "      <td>1008.341766</td>\n",
       "      <td>1246.349454</td>\n",
       "      <td>1421.444644</td>\n",
       "      <td>1685.806936</td>\n",
       "      <td>1467.789174</td>\n",
       "      <td>1680.141063</td>\n",
       "      <td>1861.537303</td>\n",
       "      <td>1958.077403</td>\n",
       "      <td>2154.315084</td>\n",
       "      <td>2248.518426</td>\n",
       "      <td>1882.518808</td>\n",
       "      <td>1648.920269</td>\n",
       "      <td>1590.555785</td>\n",
       "      <td>1735.445833</td>\n",
       "      <td>1813.609146</td>\n",
       "      <td>1688.470871</td>\n",
       "      <td>1769.171853</td>\n",
       "      <td>1788.875347</td>\n",
       "      <td>1584.333285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Angola</td>\n",
       "      <td>AGO</td>\n",
       "      <td>556.884253</td>\n",
       "      <td>527.4641105</td>\n",
       "      <td>872.6576314</td>\n",
       "      <td>982.8055874</td>\n",
       "      <td>1254.696119</td>\n",
       "      <td>1900.723809</td>\n",
       "      <td>2597.963587</td>\n",
       "      <td>3121.348725</td>\n",
       "      <td>4081.717506</td>\n",
       "      <td>3123.698885</td>\n",
       "      <td>3586.663694</td>\n",
       "      <td>4608.155166</td>\n",
       "      <td>5083.826873</td>\n",
       "      <td>5061.349253</td>\n",
       "      <td>5011.984427</td>\n",
       "      <td>3217.33924</td>\n",
       "      <td>1809.709377</td>\n",
       "      <td>2439.374439</td>\n",
       "      <td>2540.508879</td>\n",
       "      <td>2191.347764</td>\n",
       "      <td>1450.905111</td>\n",
       "      <td>1927.474078</td>\n",
       "      <td>2933.484644</td>\n",
       "      <td>2309.52162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Country_Name Country_Code    year_2000    year_2001  \\\n",
       "0                        Aruba          ABW  21026.16709  20911.19277   \n",
       "1  Africa Eastern and Southern          AFE  715.1425073  633.4733816   \n",
       "2                  Afghanistan          AFG  180.1883694  142.9033644   \n",
       "3   Africa Western and Central          AFW  527.2025617  539.2257488   \n",
       "4                       Angola          AGO   556.884253  527.4641105   \n",
       "\n",
       "     year_2002    year_2003    year_2004    year_2005    year_2006  \\\n",
       "0  21375.26912  22050.58987  24105.52412  24978.22167  25832.92556   \n",
       "1  633.5202007   819.986705  994.1938544  1130.168938  1235.847125   \n",
       "2  182.1740382  199.6432265  221.8305307   254.115276  274.0153923   \n",
       "3  627.0959153  706.4765613  850.0835822  1008.341766  1246.349454   \n",
       "4  872.6576314  982.8055874  1254.696119  1900.723809  2597.963587   \n",
       "\n",
       "     year_2007    year_2008    year_2009    year_2010    year_2011  \\\n",
       "0  27665.29948  29011.63906  25740.77023  24452.58874  26043.15633   \n",
       "1  1379.746756  1439.240924  1404.535948  1622.684093  1757.998404   \n",
       "2  376.3182996  382.5338072  453.3873851  562.4992216  608.7388504   \n",
       "3  1421.444644  1685.806936  1467.789174  1680.141063  1861.537303   \n",
       "4  3121.348725  4081.717506  3123.698885  3586.663694  4608.155166   \n",
       "\n",
       "     year_2012    year_2013    year_2014    year_2015    year_2016  \\\n",
       "0  25611.17577  26514.86898  26940.26411  28419.26453  28449.71295   \n",
       "1  1724.204053   1696.35604   1678.55361  1498.805084  1346.301281   \n",
       "2  653.4174749   638.733181  626.5129291  566.8811297   523.053012   \n",
       "3  1958.077403  2154.315084  2248.518426  1882.518808  1648.920269   \n",
       "4  5083.826873  5061.349253  5011.984427   3217.33924  1809.709377   \n",
       "\n",
       "     year_2017    year_2018    year_2019    year_2020    year_2021  \\\n",
       "0  29329.08175  30918.48358  31902.80982  24008.12782  29127.75938   \n",
       "1  1485.753579  1558.612079  1508.486886  1356.088871  1545.956697   \n",
       "2   526.140801   492.090631  497.7414313   512.055098  355.7778264   \n",
       "3  1590.555785  1735.445833  1813.609146  1688.470871  1769.171853   \n",
       "4  2439.374439  2540.508879  2191.347764  1450.905111  1927.474078   \n",
       "\n",
       "     year_2022    year_2023  \n",
       "0  33300.83882               \n",
       "1  1642.432039  1672.505957  \n",
       "2  352.6037331               \n",
       "3  1788.875347  1584.333285  \n",
       "4  2933.484644   2309.52162  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "gdp_raw_dataframe = gdp_raw_list_to_df(opening_gdp_raw(gdp_data_raw))\n",
    "gdp_raw_dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data here is longitdal, let us change it into a wide format using the python function melt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gdp_raw_to_wideformat(dataframe):  \n",
    "\n",
    "    # Defining the\n",
    "\n",
    "    gdp_raw_df_wide = pd.melt(dataframe ,id_vars=[\"Country_Name\", \"Country_Code\"], \n",
    "                        var_name= \"Year\", value_name= \"Value\")\n",
    "    \n",
    "    # we then also want to remove the year prefix..\n",
    "\n",
    "    gdp_raw_df_wide['Year'] = gdp_raw_df_wide['Year'].str.replace('year_', '')\n",
    "\n",
    "    return gdp_raw_df_wide\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Next let us check if there is missing data, we know gdp and ecnomic indicators could be sensitive infromation to some governments and they may wish to not, disclose their gdp, as well as other circumstances such as country economic state and organisation not permitting them to accurtaltely report their data. \n",
    "\n",
    "An exeprt from the world bank where this data was retrieved from states: etc\n",
    "\n",
    "from this analysis we will try a range of methods to try and see if we can impute values into this missing data. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country_Name</th>\n",
       "      <th>Country_Code</th>\n",
       "      <th>Year</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aruba</td>\n",
       "      <td>ABW</td>\n",
       "      <td>2000</td>\n",
       "      <td>21026.16709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Africa Eastern and Southern</td>\n",
       "      <td>AFE</td>\n",
       "      <td>2000</td>\n",
       "      <td>715.1425073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>2000</td>\n",
       "      <td>180.1883694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Africa Western and Central</td>\n",
       "      <td>AFW</td>\n",
       "      <td>2000</td>\n",
       "      <td>527.2025617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Angola</td>\n",
       "      <td>AGO</td>\n",
       "      <td>2000</td>\n",
       "      <td>556.884253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6379</th>\n",
       "      <td>Kosovo</td>\n",
       "      <td>XKX</td>\n",
       "      <td>2023</td>\n",
       "      <td>5943.125714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6380</th>\n",
       "      <td>Yemen, Rep.</td>\n",
       "      <td>YEM</td>\n",
       "      <td>2023</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6381</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>ZAF</td>\n",
       "      <td>2023</td>\n",
       "      <td>6253.161613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6382</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>ZMB</td>\n",
       "      <td>2023</td>\n",
       "      <td>1369.129365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6383</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>2023</td>\n",
       "      <td>1592.416574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6384 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Country_Name Country_Code  Year        Value\n",
       "0                           Aruba          ABW  2000  21026.16709\n",
       "1     Africa Eastern and Southern          AFE  2000  715.1425073\n",
       "2                     Afghanistan          AFG  2000  180.1883694\n",
       "3      Africa Western and Central          AFW  2000  527.2025617\n",
       "4                          Angola          AGO  2000   556.884253\n",
       "...                           ...          ...   ...          ...\n",
       "6379                       Kosovo          XKX  2023  5943.125714\n",
       "6380                  Yemen, Rep.          YEM  2023             \n",
       "6381                 South Africa          ZAF  2023  6253.161613\n",
       "6382                       Zambia          ZMB  2023  1369.129365\n",
       "6383                     Zimbabwe          ZWE  2023  1592.416574\n",
       "\n",
       "[6384 rows x 4 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdp_wide = gdp_raw_to_wideformat(gdp_raw_list_to_df(opening_gdp_raw(gdp_data_raw)))\n",
    "gdp_wide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some EDA, mainly of to search for missing gdp data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country_Name    244\n",
       "Country_Code    244\n",
       "Year            244\n",
       "Value           244\n",
       "dtype: int64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdp_wide[gdp_wide['Value'] == ''].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From we can tell that there are 244 rows in the dataset with, blank entries.\n",
    "Let us see which countries have the most blank entries and then we will explore appropriate iputation methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country_Name\n",
       "Afghanistan                   1\n",
       "American Samoa                3\n",
       "Aruba                         1\n",
       "Bermuda                       1\n",
       "Bhutan                        1\n",
       "British Virgin Islands       24\n",
       "Cayman Islands                7\n",
       "Channel Islands               9\n",
       "Cuba                          3\n",
       "Curacao                      12\n",
       "Eritrea                      12\n",
       "Faroe Islands                 1\n",
       "French Polynesia              1\n",
       "Gibraltar                    24\n",
       "Greenland                     2\n",
       "Guam                          3\n",
       "Isle of Man                   2\n",
       "Korea, Dem. People's Rep.    24\n",
       "Kosovo                        8\n",
       "Lebanon                       1\n",
       "Liechtenstein                 1\n",
       "Monaco                        1\n",
       "New Caledonia                 1\n",
       "Northern Mariana Islands      5\n",
       "Not classified               24\n",
       "Qatar                         1\n",
       "San Marino                    2\n",
       "Sint Maarten (Dutch part)    11\n",
       "South Sudan                  16\n",
       "St. Martin (French part)     20\n",
       "Syrian Arab Republic          2\n",
       "Tonga                         1\n",
       "Turks and Caicos Islands      1\n",
       "Venezuela, RB                 9\n",
       "Virgin Islands (U.S.)         4\n",
       "Yemen, Rep.                   5\n",
       "Name: Value, dtype: int64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdp_wide[gdp_wide['Value'] == ''].groupby(\"Country_Name\", observed =  False)[\"Value\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country_Name</th>\n",
       "      <th>Country_Code</th>\n",
       "      <th>Year</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Gibraltar</td>\n",
       "      <td>GIB</td>\n",
       "      <td>2000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>Gibraltar</td>\n",
       "      <td>GIB</td>\n",
       "      <td>2001</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>Gibraltar</td>\n",
       "      <td>GIB</td>\n",
       "      <td>2002</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>Gibraltar</td>\n",
       "      <td>GIB</td>\n",
       "      <td>2003</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1148</th>\n",
       "      <td>Gibraltar</td>\n",
       "      <td>GIB</td>\n",
       "      <td>2004</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1414</th>\n",
       "      <td>Gibraltar</td>\n",
       "      <td>GIB</td>\n",
       "      <td>2005</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>Gibraltar</td>\n",
       "      <td>GIB</td>\n",
       "      <td>2006</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1946</th>\n",
       "      <td>Gibraltar</td>\n",
       "      <td>GIB</td>\n",
       "      <td>2007</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2212</th>\n",
       "      <td>Gibraltar</td>\n",
       "      <td>GIB</td>\n",
       "      <td>2008</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2478</th>\n",
       "      <td>Gibraltar</td>\n",
       "      <td>GIB</td>\n",
       "      <td>2009</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2744</th>\n",
       "      <td>Gibraltar</td>\n",
       "      <td>GIB</td>\n",
       "      <td>2010</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3010</th>\n",
       "      <td>Gibraltar</td>\n",
       "      <td>GIB</td>\n",
       "      <td>2011</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3276</th>\n",
       "      <td>Gibraltar</td>\n",
       "      <td>GIB</td>\n",
       "      <td>2012</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3542</th>\n",
       "      <td>Gibraltar</td>\n",
       "      <td>GIB</td>\n",
       "      <td>2013</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3808</th>\n",
       "      <td>Gibraltar</td>\n",
       "      <td>GIB</td>\n",
       "      <td>2014</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4074</th>\n",
       "      <td>Gibraltar</td>\n",
       "      <td>GIB</td>\n",
       "      <td>2015</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4340</th>\n",
       "      <td>Gibraltar</td>\n",
       "      <td>GIB</td>\n",
       "      <td>2016</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4606</th>\n",
       "      <td>Gibraltar</td>\n",
       "      <td>GIB</td>\n",
       "      <td>2017</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4872</th>\n",
       "      <td>Gibraltar</td>\n",
       "      <td>GIB</td>\n",
       "      <td>2018</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5138</th>\n",
       "      <td>Gibraltar</td>\n",
       "      <td>GIB</td>\n",
       "      <td>2019</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5404</th>\n",
       "      <td>Gibraltar</td>\n",
       "      <td>GIB</td>\n",
       "      <td>2020</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5670</th>\n",
       "      <td>Gibraltar</td>\n",
       "      <td>GIB</td>\n",
       "      <td>2021</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5936</th>\n",
       "      <td>Gibraltar</td>\n",
       "      <td>GIB</td>\n",
       "      <td>2022</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6202</th>\n",
       "      <td>Gibraltar</td>\n",
       "      <td>GIB</td>\n",
       "      <td>2023</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Country_Name Country_Code  Year Value\n",
       "84      Gibraltar          GIB  2000      \n",
       "350     Gibraltar          GIB  2001      \n",
       "616     Gibraltar          GIB  2002      \n",
       "882     Gibraltar          GIB  2003      \n",
       "1148    Gibraltar          GIB  2004      \n",
       "1414    Gibraltar          GIB  2005      \n",
       "1680    Gibraltar          GIB  2006      \n",
       "1946    Gibraltar          GIB  2007      \n",
       "2212    Gibraltar          GIB  2008      \n",
       "2478    Gibraltar          GIB  2009      \n",
       "2744    Gibraltar          GIB  2010      \n",
       "3010    Gibraltar          GIB  2011      \n",
       "3276    Gibraltar          GIB  2012      \n",
       "3542    Gibraltar          GIB  2013      \n",
       "3808    Gibraltar          GIB  2014      \n",
       "4074    Gibraltar          GIB  2015      \n",
       "4340    Gibraltar          GIB  2016      \n",
       "4606    Gibraltar          GIB  2017      \n",
       "4872    Gibraltar          GIB  2018      \n",
       "5138    Gibraltar          GIB  2019      \n",
       "5404    Gibraltar          GIB  2020      \n",
       "5670    Gibraltar          GIB  2021      \n",
       "5936    Gibraltar          GIB  2022      \n",
       "6202    Gibraltar          GIB  2023      "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdp_wide[gdp_wide['Country_Name'] == 'Gibraltar']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The hard part**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cits2402-2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
